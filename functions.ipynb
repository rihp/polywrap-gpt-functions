{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from polywrap_client import PolywrapClient\n",
    "from typing import cast\n",
    "\n",
    "from pathlib import Path\n",
    "from polywrap_client import PolywrapClient, ClientConfig\n",
    "from polywrap_core import Uri, InvokerOptions, UriPackageOrWrapper, UriResolver\n",
    "from polywrap_client_config_builder import PolywrapClientConfigBuilder\n",
    "from polywrap_uri_resolvers import FsUriResolver,SimpleFileReader, StaticResolver, RecursiveResolver\n",
    "from polywrap_uri_resolvers import UriResolverAggregator\n",
    "from polywrap_http_plugin import http_plugin\n",
    "\n",
    "\n",
    "import asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ipfs_wrapper_path = Path(\"fs//Users/robertohenriquez/pycode/polywrap/hackathon/Auto-GPT/autogpt/auto_gpt_workspace/wrappers/ipfs-http-client\")\n",
    "\n",
    "\n",
    "resolver = RecursiveResolver(\n",
    "        UriResolverAggregator(\n",
    "            [\n",
    "                cast(UriResolver, FsUriResolver(file_reader=SimpleFileReader())),\n",
    "                cast(UriResolver, StaticResolver({Uri(\"wrap://ens/wraps.eth:http@1.1.0\", ipfs_wrapper_path): http_plugin()})),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "config = ClientConfig(resolver=resolver)\n",
    "client = PolywrapClient(config)\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "def polywrap_bignumber(base_number, factor):\n",
    "    \"\"\"Multiplies a base number by a factor to get a new number\"\"\"\n",
    "    uri = Uri.from_str(\n",
    "        f'fs//Users/robertohenriquez/pycode/cloud/AGI/Auto-GPT/autogpt/auto_gpt_workspace/wrappers/bignumber'\n",
    "    )\n",
    "    args = {\n",
    "        \"arg1\": str(base_number),  # The base number\n",
    "        \"obj\": {\n",
    "            \"prop1\": str(factor),  # multiply the base number by this factor\n",
    "        },\n",
    "    }\n",
    "    options: InvokerOptions[UriPackageOrWrapper] = InvokerOptions(\n",
    "        uri=uri, method=\"method\", args=args, encode_result=False\n",
    "    )\n",
    "    print(asyncio.run(client.invoke(options)))\n",
    "    result = asyncio.run(client.invoke(options))\n",
    "    return f\"the result is {result}\"\n",
    "\n",
    "def fetch_tool_library(tool_name):\n",
    "    # Mapping of keywords to tools\n",
    "    tool_mappings = {\n",
    "        \"ipfs\": [\"wrap/ipfs\"],\n",
    "        \"http\": [\"wrap/http\"],\n",
    "        \"ens\": [\"wrap/ens\"],\n",
    "        \"ethers\": [\"wrap/ethers\"],\n",
    "        \"ethereum\": [\"wrap/ethers\"],\n",
    "    }\n",
    "    \n",
    "    # Check if the tool_name has any keywords\n",
    "    keywords = tool_name.lower().split()\n",
    "    matching_tools = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        if keyword in tool_mappings:\n",
    "            matching_tools.extend(tool_mappings[keyword])\n",
    "    \n",
    "    # Remove duplicates and sort the tools alphabetically\n",
    "    matching_tools = sorted(list(set(matching_tools)))\n",
    "    \n",
    "    return str(matching_tools)\n",
    "\n",
    "def invoke_tool(options):\n",
    "    \"\"\"The invoker function that Chat GPT uses to invoke tools with polywrap\"\"\"\n",
    "    \n",
    "    uri = Uri.from_str(\n",
    "        options[\"tool_uri\"]\n",
    "    )\n",
    "    args = options[\"arguments\"]\n",
    "    method = options[\"method\"]\n",
    "    options: InvokerOptions[UriPackageOrWrapper] = InvokerOptions(\n",
    "        uri=uri, method=method, args=args, encode_result=False\n",
    "    )\n",
    "    print(asyncio.run(client.invoke(options)))\n",
    "    result = asyncio.run(client.invoke(options))\n",
    "    return f\"SUCCESS! The result is: {result}\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_conversation(question, functions):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[{\"role\": \"user\", \"content\": question}],\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",\n",
    "    )\n",
    "\n",
    "    message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    if message.get(\"function_call\"):\n",
    "        print(\"-> Using a function call now\")\n",
    "        function_name = message[\"function_call\"][\"name\"]\n",
    "        function_args_string = message[\"function_call\"][\"arguments\"]\n",
    "        function_args = json.loads(function_args_string)\n",
    "\n",
    "        function_response = globals()[function_name](**function_args)\n",
    "\n",
    "        print(message)\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"What is the result of the initial question?\"},\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": function_response,\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        return second_response\n",
    "    else:\n",
    "        raise Exception(\"The wrapper was not invoked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Using a function call now\n",
      "{\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"arguments\": \"{\\n  \\\"tool_name\\\": \\\"ipfs\\\"\\n}\",\n",
      "    \"name\": \"fetch_tool_library\"\n",
      "  },\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"The result of the initial question is 'wrap/ipfs'.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1687353517,\n",
      "  \"id\": \"chatcmpl-7Ts1FfKyAsHv7F6E46fB3nB0xtVKN\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 12,\n",
      "    \"prompt_tokens\": 25,\n",
      "    \"total_tokens\": 37\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"Find what tools are available for ipfs\"\n",
    "# Define the functions for our ChatGPT Agent\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"polywrap_bignumber\",\n",
    "        \"description\": \"Use this function every time you need to make a multiplication\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"base_number\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The base number\",\n",
    "                },\n",
    "                \"factor\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The factor to multiply the base number\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"base_number\", \"factor\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"fetch_tool_library\",\n",
    "        \"description\": \"Fetches information about a specific tool from the tool library, given the tool name.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"tool_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the tool to fetch\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"tool_name\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"invoke_tool\",\n",
    "        \"description\": \"Invokes the given tool with the specified arguments\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"options\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"description\": \"The options to pass to the tool, including the tool_uri and the arguments\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"tool_uri\", \"options\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "print(run_conversation(question, functions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Using a function call now\n",
      "{\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"arguments\": \"{\\n  \\\"tool_name\\\": \\\"http\\\"\\n}\",\n",
      "    \"name\": \"fetch_tool_library\"\n",
      "  },\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"The result of the initial question is that the concept of wrapping and unwrapping URLs is referred to as 'wrap/http'.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1687353519,\n",
      "  \"id\": \"chatcmpl-7Ts1HQzc6jrJwwrZR7s1lwMTas3vX\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 25,\n",
      "    \"prompt_tokens\": 24,\n",
      "    \"total_tokens\": 49\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"Find what tools are available for http in our skill library\"\n",
    "print(run_conversation(question, functions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Using a function call now\n",
      "{\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"arguments\": \"{\\n  \\\"tool_name\\\": \\\"ENS\\\"\\n}\",\n",
      "    \"name\": \"fetch_tool_library\"\n",
      "  },\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"I apologize, but I'm unable to understand the context of your question. Could you please provide more information or rephrase your question?\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1687353521,\n",
      "  \"id\": \"chatcmpl-7Ts1JUHo8DB828NylzlfNzjz2vCes\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 27,\n",
      "    \"prompt_tokens\": 25,\n",
      "    \"total_tokens\": 52\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"Find what tools are available for ENS in our skill library\"\n",
    "print(run_conversation(question, functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Using a function call now\n",
      "{\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"arguments\": \"{\\n\\\"tool_name\\\": \\\"ethereum\\\"\\n}\",\n",
      "    \"name\": \"fetch_tool_library\"\n",
      "  },\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"The result of the initial question is not clear as it seems to be incomplete. It is asking about the result of something related to \\\"wrap/ethers,\\\" but without additional context or clarification, it is difficult to determine a specific result.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1687353523,\n",
      "  \"id\": \"chatcmpl-7Ts1LQbIu9Rgi8AHwYSHN0m3D0SfW\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 48,\n",
      "    \"prompt_tokens\": 26,\n",
      "    \"total_tokens\": 74\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"Find what tools are available for ethereum in the skill library\"\n",
    "print(run_conversation(question, functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Using a function call now\n",
      "[{'role': 'user', 'content': 'Find what tools are available for ipfs in the skill library'}, {'role': 'assistant', 'content': \"['wrap/ipfs']\"}]\n",
      "-> Using a function call now\n",
      "[{'role': 'user', 'content': 'Find what tools are available for ipfs in the skill library'}, {'role': 'assistant', 'content': \"['wrap/ipfs']\"}, {'role': 'user', 'content': \"Call the function invoke_tool to the received URI with the arguments: {method: get, arguments: {hash: 'Qm11234'}, tool_uri: <the found URI>}\"}, {'role': 'assistant', 'content': \"Error: invoke_tool() missing 1 required positional argument: 'options'\"}] {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"function_call\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"arguments\": \"{}\",\n",
      "          \"name\": \"invoke_tool\"\n",
      "        },\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1687354240,\n",
      "  \"id\": \"chatcmpl-7TsCu5qcgXJCMbMeAXG3zIBZi6IYV\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 7,\n",
      "    \"prompt_tokens\": 198,\n",
      "    \"total_tokens\": 205\n",
      "  }\n",
      "}\n",
      "-> Using a function call now\n",
      "-> Using a function call now\n",
      "-> Using a function call now\n",
      "-> Using a function call now\n",
      "-> Using a function call now\n",
      "-> No function call used\n",
      "-> No function call used\n",
      "-> No function call used\n",
      "-> No function call used\n",
      "-> Using a function call now\n",
      "-> Using a function call now\n",
      "-> No function call used\n",
      "-> No function call used\n",
      "-> No function call used\n",
      "-> Using a function call now\n",
      "-> Using a function call now\n",
      "-> Using a function call now\n",
      "-> No function call used\n",
      "-> Using a function call now\n",
      "-> Using a function call now\n",
      "[{'role': 'user', 'content': 'Find what tools are available for ipfs in the skill library'}, {'role': 'assistant', 'content': \"['wrap/ipfs']\"}, {'role': 'user', 'content': \"Call the function invoke_tool to the received URI with the arguments: {method: get, arguments: {hash: 'Qm11234'}, tool_uri: <the found URI>}\"}, {'role': 'assistant', 'content': \"Error: invoke_tool() missing 1 required positional argument: 'options'\"}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': \"Error: invoke_tool() missing 1 required positional argument: 'options'\"}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: \\n                Error resolving URI \"wrap://wrap/ipfs\"\\n                URI not found\\n                Resolution Stack: [\\n  \"wrap://wrap/ipfs => UriResolverAggregator\",\\n  [\\n    \"wrap://wrap/ipfs => StaticResolver - Miss\"\\n  ]\\n]\\n'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': '[]'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': \"Error: invoke_tool() missing 1 required positional argument: 'options'\"}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': '[]'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': 'Error: not enough values to unpack (expected 2, got 1)'}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': \"Error: invoke_tool() missing 1 required positional argument: 'options'\"}, {'role': 'user', 'content': 'Try to call the invoke_tool function again with the provided feedback until you get the success result'}, {'role': 'assistant', 'content': \"Error: invoke_tool() missing 1 required positional argument: 'options'\"}]\n"
     ]
    }
   ],
   "source": [
    "def agent_loop(question, functions, chat_history=None):\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=chat_history,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",\n",
    "    )\n",
    "\n",
    "    message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    if message.get(\"function_call\"):\n",
    "        print(\"-> Using a function call now\")\n",
    "        function_name = message[\"function_call\"][\"name\"]\n",
    "        function_args_string = message[\"function_call\"][\"arguments\"]\n",
    "        function_args = json.loads(function_args_string)\n",
    "\n",
    "        try:\n",
    "            function_response = globals()[function_name](**function_args)\n",
    "            updated_chat_history = [{\"role\": \"assistant\", \"content\": function_response}]\n",
    "            chat_history.extend(updated_chat_history)\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            updated_chat_history = [{\"role\": \"assistant\", \"content\": f\"Error: {error_message}\"}]\n",
    "            chat_history.extend(updated_chat_history)\n",
    "    else:\n",
    "        print(\"-> No function call used\")\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": message[\"content\"]})\n",
    "        return response, chat_history\n",
    "\n",
    "    return response, chat_history\n",
    "\n",
    "\n",
    "# Example usage\n",
    "question = \"Find what tools are available for ipfs in the skill library\"\n",
    "response, chat_history = agent_loop(question, functions)\n",
    "\n",
    "print(chat_history)\n",
    "\n",
    "# Continue the conversation\n",
    "new_question = \"Call the function invoke_tool to the received URI with the arguments: {method: get, arguments: {hash: 'Qm11234'}, tool_uri: <the found URI>}\"\n",
    "response, chat_history = agent_loop(new_question, functions, chat_history)\n",
    "\n",
    "# Continue the conversation further if needed\n",
    "print(chat_history, response)\n",
    "\n",
    "# Example usage\n",
    "for i in range(20):\n",
    "    new_question = \"Try to call the invoke_tool function again with the provided feedback until you get the success result\"\n",
    "    response, chat_history = agent_loop(new_question, functions, chat_history)\n",
    "\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
